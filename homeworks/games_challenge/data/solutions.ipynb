{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1585a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "941d9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_steamspy = pd.read_csv('output_steamspy.csv')\n",
    "steamstore = pd.read_csv('steam_store_data_2024.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66783bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>app_id</th>\n",
       "      <th>content</th>\n",
       "      <th>author_id</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>340</td>\n",
       "      <td>GG</td>\n",
       "      <td>76561198152563064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>630</td>\n",
       "      <td>its fun</td>\n",
       "      <td>76561198006953365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>730</td>\n",
       "      <td>POKAZUJE ZE MAM PIERDOLONE 15 PINGU A CALY CZA...</td>\n",
       "      <td>76561199082720424</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>730</td>\n",
       "      <td>this game suck its not the game its self its t...</td>\n",
       "      <td>76561198305268228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>Kind of difficult to play without the source u...</td>\n",
       "      <td>76561198207922887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140800</th>\n",
       "      <td>140801</td>\n",
       "      <td>10</td>\n",
       "      <td>я стрелял меня насиловали</td>\n",
       "      <td>76561198412836420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140801</th>\n",
       "      <td>140802</td>\n",
       "      <td>240</td>\n",
       "      <td>This game is gold\\n</td>\n",
       "      <td>76561199335981839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140802</th>\n",
       "      <td>140803</td>\n",
       "      <td>550</td>\n",
       "      <td>The best zombie horde shooter to this day, I w...</td>\n",
       "      <td>76561199030428167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140803</th>\n",
       "      <td>140804</td>\n",
       "      <td>570</td>\n",
       "      <td>vvvvvv</td>\n",
       "      <td>76561199229539481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140804</th>\n",
       "      <td>140805</td>\n",
       "      <td>730</td>\n",
       "      <td>get rid of the hackers\\nfix tf2\\nand for the l...</td>\n",
       "      <td>76561198879829571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140805 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  app_id  ...          author_id  is_positive\n",
       "0            1     340  ...  76561198152563064            1\n",
       "1            2     630  ...  76561198006953365            1\n",
       "2            3     730  ...  76561199082720424            0\n",
       "3            4     730  ...  76561198305268228            0\n",
       "4            5      30  ...  76561198207922887            0\n",
       "...        ...     ...  ...                ...          ...\n",
       "140800  140801      10  ...  76561198412836420            1\n",
       "140801  140802     240  ...  76561199335981839            1\n",
       "140802  140803     550  ...  76561199030428167            1\n",
       "140803  140804     570  ...  76561199229539481            0\n",
       "140804  140805     730  ...  76561198879829571            0\n",
       "\n",
       "[140805 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8bb7330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140805 entries, 0 to 140804\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   id           140805 non-null  int64 \n",
      " 1   app_id       140805 non-null  int64 \n",
      " 2   content      140495 non-null  object\n",
      " 3   author_id    140805 non-null  int64 \n",
      " 4   is_positive  140805 non-null  int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84069563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60346 entries, 0 to 60345\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         60346 non-null  int64 \n",
      " 1   app_id     60346 non-null  int64 \n",
      " 2   content    60228 non-null  object\n",
      " 3   author_id  60346 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9484157c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60346 entries, 0 to 60345\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         60346 non-null  int64 \n",
      " 1   app_id     60346 non-null  int64 \n",
      " 2   content    60346 non-null  object\n",
      " 3   author_id  60346 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#replace Nan in test.content with empty string\n",
    "test['content'] = test['content'].fillna('')\n",
    "\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc7dac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "df = train.copy()\n",
    "df = df.dropna(subset=['content'])    # Удалим строки с пустым контентом\n",
    "\n",
    "# Выбор признаков и метки\n",
    "X = df['content']\n",
    "y = df['is_positive']\n",
    "\n",
    "# Разделение на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Преобразование текста в TF-IDF векторы\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), decode_error=\"strict\")  # можно поиграть с параметрами\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2db7d733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7616997046158226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.61      0.71     13686\n",
      "           1       0.71      0.90      0.80     14413\n",
      "\n",
      "    accuracy                           0.76     28099\n",
      "   macro avg       0.78      0.76      0.75     28099\n",
      "weighted avg       0.78      0.76      0.76     28099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели логистической регрессии\n",
    "#model = LogisticRegression(max_iter=1000)\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Предсказание и оценка\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13c87e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Logistic Regression): 0.851916438307413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84     13686\n",
      "           1       0.83      0.89      0.86     14413\n",
      "\n",
      "    accuracy                           0.85     28099\n",
      "   macro avg       0.85      0.85      0.85     28099\n",
      "weighted avg       0.85      0.85      0.85     28099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = LogisticRegression(max_iter=1000)\n",
    "model1.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred1 = model1.predict(X_test_tfidf)\n",
    "print(\"Accuracy (Logistic Regression):\", accuracy_score(y_test, y_pred1))\n",
    "print(classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a5b5809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Random Forest): 0.8298160076871063\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82     13686\n",
      "           1       0.82      0.86      0.84     14413\n",
      "\n",
      "    accuracy                           0.83     28099\n",
      "   macro avg       0.83      0.83      0.83     28099\n",
      "weighted avg       0.83      0.83      0.83     28099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model2.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred2 = model2.predict(X_test_tfidf)\n",
    "print(\"Accuracy (Random Forest):\", accuracy_score(y_test, y_pred2))\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bbf89605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# используем модель для предсказания на тестовых данных\n",
    "X_test_final = test['content']\n",
    "X_test_final_tfidf = vectorizer.transform(X_test_final)\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_test_final_pred = model.predict(X_test_final_tfidf)\n",
    "# Сохранение предсказаний в файл\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'sentiment': y_test_final_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fea48f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61d9f02",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44f5a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import re\n",
    "\n",
    "# Очистка и токенизация\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text.lower())\n",
    "    return text.split()\n",
    "\n",
    "df_ft = train.copy()\n",
    "\n",
    "# Выбор признаков и метки\n",
    "X = df['content'] \n",
    "y = df['is_positive']\n",
    "\n",
    "# Разделение на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Токенизация\n",
    "X_train_tokens = X_train.apply(preprocess)\n",
    "X_test_tokens = X_test.apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8aec105",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = FastText(sentences=X_train_tokens, vector_size=200, window=5, min_count=1, sg=1, epochs=10)\n",
    "\n",
    "# Преобразование текстов в векторы\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf037979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_text(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Преобразование текста в векторы\n",
    "X_train_vectors = np.array([vectorize_text(tokens, ft_model) for tokens in X_train_tokens])\n",
    "X_test_vectors = np.array([vectorize_text(tokens, ft_model) for tokens in X_test_tokens])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "762849e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Logistic Regression with FastText): 0.819993594078081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82     13686\n",
      "           1       0.83      0.82      0.82     14413\n",
      "\n",
      "    accuracy                           0.82     28099\n",
      "   macro avg       0.82      0.82      0.82     28099\n",
      "weighted avg       0.82      0.82      0.82     28099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(max_iter=1000)\n",
    "model_lr.fit(X_train_vectors, y_train)\n",
    "y_pred_lr = model_lr.predict(X_test_vectors)\n",
    "print(\"Accuracy (Logistic Regression with FastText):\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a85e2",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84e48bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f08ede7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140805 entries, 0 to 140804\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   id           140805 non-null  int64 \n",
      " 1   app_id       140805 non-null  object\n",
      " 2   content      140495 non-null  object\n",
      " 3   author_id    140805 non-null  int64 \n",
      " 4   is_positive  140805 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train['app_id'] = train['app_id'].astype(str)\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ab548a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140805 entries, 0 to 140804\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   id           140805 non-null  int64 \n",
      " 1   app_id       140805 non-null  object\n",
      " 2   content      140805 non-null  object\n",
      " 3   author_id    140805 non-null  int64 \n",
      " 4   is_positive  140805 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train['content'] = train['content'].fillna('')\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90cc5231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\spbu-ml\\.venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\GitHub\\spbu-ml\\.venv\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\GitHub\\spbu-ml\\.venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\GitHub\\spbu-ml\\.venv\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "def get_text_length(x):\n",
    "    return np.array([len(t) for t in x]).reshape(-1, 1)\n",
    "\n",
    "def get_word_count(x):\n",
    "    return np.array([len(word_tokenize(t)) for t in x]).reshape(-1, 1)\n",
    "\n",
    "def get_unique_word_count(x):\n",
    "    return np.array([len(set(word_tokenize(t))) for t in x]).reshape(-1, 1)\n",
    "\n",
    "def mean_word_length(x):\n",
    "    return np.array([np.mean([len(w) for w in word_tokenize(t)]) for t in x]).reshape(-1, 1)\n",
    "\n",
    "def mean_syllable_count(x):\n",
    "    return np.array([np.mean([len(list(filter(lambda x: x.lower() in 'aeiouy', w))) for w in word_tokenize(t)]) for t in x]).reshape(-1, 1)\n",
    "\n",
    "def get_sentences_count(x):\n",
    "    return np.array([len(x.split('.')) for x in x]).reshape(-1, 1)\n",
    "\n",
    "def vocabulary_size(x):\n",
    "    return np.array([len(set(word_tokenize(x))) for x in x]).reshape(-1, 1)\n",
    "\n",
    "train['text_length'] = get_text_length(train['content'])\n",
    "train['word_count'] = get_word_count(train['content'])\n",
    "train['unique_word_count'] = get_unique_word_count(train['content'])\n",
    "train['mean_word_length'] = mean_word_length(train['content'])\n",
    "train['mean_syllable_count'] = mean_syllable_count(train['content'])\n",
    "train['sentences_count'] = get_sentences_count(train['content'])\n",
    "train['vocabulary_size'] = vocabulary_size(train['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecf4663e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>app_id</th>\n",
       "      <th>content</th>\n",
       "      <th>author_id</th>\n",
       "      <th>is_positive</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>mean_syllable_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>vocabulary_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>340</td>\n",
       "      <td>GG</td>\n",
       "      <td>76561198152563064</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>630</td>\n",
       "      <td>its fun</td>\n",
       "      <td>76561198006953365</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>730</td>\n",
       "      <td>POKAZUJE ZE MAM PIERDOLONE 15 PINGU A CALY CZA...</td>\n",
       "      <td>76561199082720424</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>4.588235</td>\n",
       "      <td>2.058824</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>730</td>\n",
       "      <td>this game suck its not the game its self its t...</td>\n",
       "      <td>76561198305268228</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>4.113636</td>\n",
       "      <td>1.613636</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>Kind of difficult to play without the source u...</td>\n",
       "      <td>76561198207922887</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>3.789474</td>\n",
       "      <td>1.421053</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140800</th>\n",
       "      <td>140801</td>\n",
       "      <td>10</td>\n",
       "      <td>я стрелял меня насиловали</td>\n",
       "      <td>76561198412836420</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140801</th>\n",
       "      <td>140802</td>\n",
       "      <td>240</td>\n",
       "      <td>This game is gold\\n</td>\n",
       "      <td>76561199335981839</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140802</th>\n",
       "      <td>140803</td>\n",
       "      <td>550</td>\n",
       "      <td>The best zombie horde shooter to this day, I w...</td>\n",
       "      <td>76561199030428167</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140803</th>\n",
       "      <td>140804</td>\n",
       "      <td>570</td>\n",
       "      <td>vvvvvv</td>\n",
       "      <td>76561199229539481</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140804</th>\n",
       "      <td>140805</td>\n",
       "      <td>730</td>\n",
       "      <td>get rid of the hackers\\nfix tf2\\nand for the l...</td>\n",
       "      <td>76561198879829571</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140805 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id app_id  ... sentences_count  vocabulary_size\n",
       "0            1    340  ...               1                1\n",
       "1            2    630  ...               1                2\n",
       "2            3    730  ...               1               16\n",
       "3            4    730  ...               1               33\n",
       "4            5     30  ...               3               17\n",
       "...        ...    ...  ...             ...              ...\n",
       "140800  140801     10  ...               1                4\n",
       "140801  140802    240  ...               1                4\n",
       "140802  140803    550  ...               1               15\n",
       "140803  140804    570  ...               1                1\n",
       "140804  140805    730  ...               1               16\n",
       "\n",
       "[140805 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f4b3e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140805 entries, 0 to 140804\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   id                   140805 non-null  int64  \n",
      " 1   app_id               140805 non-null  object \n",
      " 2   content              140805 non-null  object \n",
      " 3   author_id            140805 non-null  int64  \n",
      " 4   is_positive          140805 non-null  int64  \n",
      " 5   text_length          140805 non-null  int32  \n",
      " 6   word_count           140805 non-null  int32  \n",
      " 7   unique_word_count    140805 non-null  int32  \n",
      " 8   mean_word_length     140805 non-null  float64\n",
      " 9   mean_syllable_count  140805 non-null  float64\n",
      " 10  sentences_count      140805 non-null  int32  \n",
      " 11  vocabulary_size      140805 non-null  int32  \n",
      "dtypes: float64(2), int32(5), int64(3), object(2)\n",
      "memory usage: 10.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#replace NaN values with 0\n",
    "train = train.fillna(0)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed0d8d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>content</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>mean_syllable_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>vocabulary_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66140</th>\n",
       "      <td>240</td>\n",
       "      <td>bought this game ages ago for gmod textures</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75301</th>\n",
       "      <td>240</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115162</th>\n",
       "      <td>620</td>\n",
       "      <td>please gieve refund frined gave game and i wan...</td>\n",
       "      <td>109</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22128</th>\n",
       "      <td>280</td>\n",
       "      <td>---{Graphics}---\\n☐ You forget what reality is...</td>\n",
       "      <td>1341</td>\n",
       "      <td>341</td>\n",
       "      <td>165</td>\n",
       "      <td>3.152493</td>\n",
       "      <td>1.126100</td>\n",
       "      <td>2</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55317</th>\n",
       "      <td>730</td>\n",
       "      <td>děkuji dotal jsem penalizaci za dřívější leavn...</td>\n",
       "      <td>90</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.923077</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110268</th>\n",
       "      <td>440</td>\n",
       "      <td>Yerp.</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>30</td>\n",
       "      <td>Has an older community in it, not much young b...</td>\n",
       "      <td>286</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103694</th>\n",
       "      <td>300</td>\n",
       "      <td>eh.</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>70</td>\n",
       "      <td>ew (i have a headache)</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>550</td>\n",
       "      <td>great game great scenario great ambiance</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112644 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       app_id  ... vocabulary_size\n",
       "66140     240  ...               8\n",
       "75301     240  ...               1\n",
       "115162    620  ...              17\n",
       "22128     280  ...             165\n",
       "55317     730  ...              13\n",
       "...       ...  ...             ...\n",
       "110268    440  ...               2\n",
       "119879     30  ...              48\n",
       "103694    300  ...               2\n",
       "131932     70  ...               7\n",
       "121958    550  ...               4\n",
       "\n",
       "[112644 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(columns=['is_positive', 'id', 'author_id'])\n",
    "y = train['is_positive']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "26dbe6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;text&#x27;,\n",
       "                                                  TfidfVectorizer(max_features=10000,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               2)),\n",
       "                                                  &#x27;content&#x27;),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;app_id&#x27;]),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;text_length&#x27;, &#x27;word_count&#x27;,\n",
       "                                                   &#x27;unique_word_count&#x27;,\n",
       "                                                   &#x27;mean_word_length&#x27;,\n",
       "                                                   &#x27;mean_syllable_count&#x27;,\n",
       "                                                   &#x27;sentences_count&#x27;,\n",
       "                                                   &#x27;vocabulary_size&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, GradientBoostingClassifier(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;text&#x27;,\n",
       "                                                  TfidfVectorizer(max_features=10000,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               2)),\n",
       "                                                  &#x27;content&#x27;),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;app_id&#x27;]),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;text_length&#x27;, &#x27;word_count&#x27;,\n",
       "                                                   &#x27;unique_word_count&#x27;,\n",
       "                                                   &#x27;mean_word_length&#x27;,\n",
       "                                                   &#x27;mean_syllable_count&#x27;,\n",
       "                                                   &#x27;sentences_count&#x27;,\n",
       "                                                   &#x27;vocabulary_size&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, GradientBoostingClassifier(random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessor: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;text&#x27;,\n",
       "                                 TfidfVectorizer(max_features=10000,\n",
       "                                                 ngram_range=(1, 2)),\n",
       "                                 &#x27;content&#x27;),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;app_id&#x27;]),\n",
       "                                (&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;text_length&#x27;, &#x27;word_count&#x27;,\n",
       "                                  &#x27;unique_word_count&#x27;, &#x27;mean_word_length&#x27;,\n",
       "                                  &#x27;mean_syllable_count&#x27;, &#x27;sentences_count&#x27;,\n",
       "                                  &#x27;vocabulary_size&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>text</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>content</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(max_features=10000, ngram_range=(1, 2))</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;app_id&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;text_length&#x27;, &#x27;word_count&#x27;, &#x27;unique_word_count&#x27;, &#x27;mean_word_length&#x27;, &#x27;mean_syllable_count&#x27;, &#x27;sentences_count&#x27;, &#x27;vocabulary_size&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GradientBoostingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(random_state=42)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('text',\n",
       "                                                  TfidfVectorizer(max_features=10000,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               2)),\n",
       "                                                  'content'),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['app_id']),\n",
       "                                                 ('num', StandardScaler(),\n",
       "                                                  ['text_length', 'word_count',\n",
       "                                                   'unique_word_count',\n",
       "                                                   'mean_word_length',\n",
       "                                                   'mean_syllable_count',\n",
       "                                                   'sentences_count',\n",
       "                                                   'vocabulary_size'])])),\n",
       "                ('classifier', GradientBoostingClassifier(random_state=42))])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create a preprocessing pipeline that will handle both text and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(max_features=10000, ngram_range=(1, 2)), 'content'),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['app_id']),  # Use a list for column names\n",
    "        ('num', StandardScaler(), ['text_length', 'word_count', 'unique_word_count', \n",
    "                                    'mean_word_length', 'mean_syllable_count', \n",
    "                                    'sentences_count', 'vocabulary_size'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Create the full pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "59815c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8707787365505486\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.79      0.86     13648\n",
      "           1       0.83      0.95      0.88     14513\n",
      "\n",
      "    accuracy                           0.87     28161\n",
      "   macro avg       0.88      0.87      0.87     28161\n",
      "weighted avg       0.88      0.87      0.87     28161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = pipeline.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "y_val_report = classification_report(y_val, y_val_pred)\n",
    "print(\"Validation Classification Report:\\n\", y_val_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2881de91",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d404fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train['app_id'] = train['app_id'].astype(str)\n",
    "train['content'] = train['content'].fillna('')\n",
    "\n",
    "# Очистка текста\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zа-яё0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "train['content'] = train['content'].astype(str).apply(clean_text)\n",
    "\n",
    "\n",
    "\n",
    "def get_text_length(x): return np.array([len(t) for t in x]).reshape(-1, 1)\n",
    "def get_word_count(x): return np.array([len(word_tokenize(t)) for t in x]).reshape(-1, 1)\n",
    "def get_unique_word_count(x): return np.array([len(set(word_tokenize(t))) for t in x]).reshape(-1, 1)\n",
    "def mean_word_length(x): return np.array([np.mean([len(w) for w in word_tokenize(t)]) for t in x]).reshape(-1, 1)\n",
    "def mean_syllable_count(x): return np.array([\n",
    "    np.mean([sum(1 for c in w if c.lower() in 'aeiouyаеёиоуыэюя') for w in word_tokenize(t)]) for t in x\n",
    "]).reshape(-1, 1)\n",
    "def get_sentences_count(x): return np.array([len(re.split(r'[.!?]', t)) for t in x]).reshape(-1, 1)\n",
    "def vocabulary_size(x): return np.array([len(set(word_tokenize(t))) for t in x]).reshape(-1, 1)\n",
    "\n",
    "train['text_length'] = get_text_length(train['content'])\n",
    "train['word_count'] = get_word_count(train['content'])\n",
    "train['unique_word_count'] = get_unique_word_count(train['content'])\n",
    "train['mean_word_length'] = mean_word_length(train['content'])\n",
    "train['mean_syllable_count'] = mean_syllable_count(train['content'])\n",
    "train['sentences_count'] = get_sentences_count(train['content'])\n",
    "train['vocabulary_size'] = vocabulary_size(train['content'])\n",
    "\n",
    "train = train.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "X = train.drop(columns=['is_positive', 'id', 'author_id'])\n",
    "y = train['is_positive']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(max_features=15000, ngram_range=(1, 2), stop_words='english'), 'content'),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['app_id']),\n",
    "        ('num', StandardScaler(), ['text_length', 'word_count', 'unique_word_count',\n",
    "                                   'mean_word_length', 'mean_syllable_count',\n",
    "                                   'sentences_count', 'vocabulary_size'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "acc = accuracy_score(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fdcb30",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae4353c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Загрузка данных\n",
    "train = pd.read_csv('train.csv')\n",
    "train['app_id'] = train['app_id'].astype(str)\n",
    "train['content'] = train['content'].fillna('')\n",
    "\n",
    "# Очистка текста\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zа-яё0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "train['content'] = train['content'].astype(str).apply(clean_text)\n",
    "\n",
    "# Дополнительные фичи\n",
    "def get_text_length(x): return np.array([len(t) for t in x]).reshape(-1, 1)\n",
    "def get_word_count(x): return np.array([len(word_tokenize(t)) for t in x]).reshape(-1, 1)\n",
    "def get_unique_word_count(x): return np.array([len(set(word_tokenize(t))) for t in x]).reshape(-1, 1)\n",
    "def mean_word_length(x): return np.array([np.mean([len(w) for w in word_tokenize(t)]) if len(word_tokenize(t)) > 0 else 0 for t in x]).reshape(-1, 1)\n",
    "def mean_syllable_count(x): return np.array([np.mean([len(list(filter(lambda x: x.lower() in 'aeiouy', w))) for w in word_tokenize(t)]) if len(word_tokenize(t)) > 0 else 0 for t in x]).reshape(-1, 1)\n",
    "def get_sentences_count(x): return np.array([len(x.split('.')) for x in x]).reshape(-1, 1)\n",
    "def vocabulary_size(x): return np.array([len(set(word_tokenize(x))) for x in x]).reshape(-1, 1)\n",
    "def count_exclamations(x): return np.array([t.count('!') for t in x]).reshape(-1, 1)\n",
    "def count_questions(x): return np.array([t.count('?') for t in x]).reshape(-1, 1)\n",
    "def count_not(x): return np.array([t.lower().count('not') for t in x]).reshape(-1, 1)\n",
    "def count_but(x): return np.array([t.lower().count('but') for t in x]).reshape(-1, 1)\n",
    "\n",
    "# Добавление фичей\n",
    "train['text_length'] = get_text_length(train['content'])\n",
    "train['word_count'] = get_word_count(train['content'])\n",
    "train['unique_word_count'] = get_unique_word_count(train['content'])\n",
    "train['mean_word_length'] = mean_word_length(train['content'])\n",
    "train['mean_syllable_count'] = mean_syllable_count(train['content'])\n",
    "train['sentences_count'] = get_sentences_count(train['content'])\n",
    "train['vocabulary_size'] = vocabulary_size(train['content'])\n",
    "train['count_exclamations'] = count_exclamations(train['content'])\n",
    "train['count_questions'] = count_questions(train['content'])\n",
    "train['count_not'] = count_not(train['content'])\n",
    "train['count_but'] = count_but(train['content'])\n",
    "\n",
    "# Целевая переменная и разбиение\n",
    "X = train.drop(columns=['is_positive', 'id', 'author_id'])\n",
    "y = train['is_positive']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Подготовка TF-IDF векторайзеров\n",
    "word_vectorizer = ('word_tfidf', TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english',\n",
    "    analyzer='word'\n",
    "), 'content')\n",
    "\n",
    "char_vectorizer = ('char_tfidf', TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(3, 5),\n",
    "    analyzer='char_wb'\n",
    "), 'content')\n",
    "\n",
    "# Числовые признаки\n",
    "numeric_features = [\n",
    "    'text_length', 'word_count', 'unique_word_count',\n",
    "    'mean_word_length', 'mean_syllable_count',\n",
    "    'sentences_count', 'vocabulary_size',\n",
    "    'count_exclamations', 'count_questions',\n",
    "    'count_not', 'count_but'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a887f34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9446965661730763\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     68938\n",
      "           1       0.94      0.96      0.95     71867\n",
      "\n",
      "    accuracy                           0.94    140805\n",
      "   macro avg       0.95      0.94      0.94    140805\n",
      "weighted avg       0.94      0.94      0.94    140805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "# Предобработка\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        word_vectorizer,\n",
    "        char_vectorizer,\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['app_id']),\n",
    "        ('num', MinMaxScaler(), numeric_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Базовые классификаторы для ансамбля\n",
    "estimators = [\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('nb', MultinomialNB())  # NB работает только на неотрицательных данных — TF-IDF\n",
    "]\n",
    "\n",
    "# Ансамбль\n",
    "stacking = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(max_iter=1000),\n",
    "    passthrough=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Полный пайплайн\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', stacking)\n",
    "])\n",
    "\n",
    "# Обучение\n",
    "#pipeline.fit(X_train, y_train)\n",
    "#pipeline.fit(X, y)\n",
    "\n",
    "from joblib import load\n",
    "pipeline = load('C:\\GitHub\\spbu-ml\\spbu_ml_2025\\homeworks\\games_challenge\\data/text_classification_pipeline.pkl')\n",
    "\n",
    "# Оценка\n",
    "y_pred = pipeline.predict(X)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08414d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_classification_pipeline.pkl']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test['app_id'] = test['app_id'].astype(str)\n",
    "test['content'] = test['content'].fillna('')\n",
    "\n",
    "# Очистка текста\n",
    "test['content'] = test['content'].astype(str).apply(clean_text)\n",
    "\n",
    "# Добавление тех же фичей, что и в тренировочном наборе\n",
    "test['text_length'] = get_text_length(test['content'])\n",
    "test['word_count'] = get_word_count(test['content'])\n",
    "test['unique_word_count'] = get_unique_word_count(test['content'])\n",
    "test['mean_word_length'] = mean_word_length(test['content'])\n",
    "test['mean_syllable_count'] = mean_syllable_count(test['content'])\n",
    "test['sentences_count'] = get_sentences_count(test['content'])\n",
    "test['vocabulary_size'] = vocabulary_size(test['content'])\n",
    "test['count_exclamations'] = count_exclamations(test['content'])\n",
    "test['count_questions'] = count_questions(test['content'])\n",
    "test['count_not'] = count_not(test['content'])\n",
    "test['count_but'] = count_but(test['content'])\n",
    "\n",
    "# Преобразование тестовых данных\n",
    "X_test_final = test.drop(columns=['id', 'author_id'])\n",
    "\n",
    "# Применение пайплайна к тестовым данным\n",
    "y_test_final_pred = pipeline.predict(X_test_final)\n",
    "\n",
    "# Сохранение предсказаний в файл\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'sentiment': y_test_final_pred\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "# Сохранение модели\n",
    "import joblib\n",
    "joblib.dump(pipeline, 'text_classification_pipeline.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
